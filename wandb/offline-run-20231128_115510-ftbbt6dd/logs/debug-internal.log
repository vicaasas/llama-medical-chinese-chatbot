2023-11-28 11:55:10,970 INFO    StreamThr :19815 [internal.py:wandb_internal():86] W&B internal server running at pid: 19815, started at: 2023-11-28 11:55:10.969273
2023-11-28 11:55:10,972 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status
2023-11-28 11:55:10,973 INFO    WriterThread:19815 [datastore.py:open_for_write():85] open: /work/u5516210/llama-medical-chinese-chatbot/wandb/offline-run-20231128_115510-ftbbt6dd/run-ftbbt6dd.wandb
2023-11-28 11:55:11,022 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: run_start
2023-11-28 11:55:11,027 DEBUG   HandlerThread:19815 [system_info.py:__init__():32] System info init
2023-11-28 11:55:11,028 DEBUG   HandlerThread:19815 [system_info.py:__init__():47] System info init done
2023-11-28 11:55:11,028 INFO    HandlerThread:19815 [system_monitor.py:start():194] Starting system monitor
2023-11-28 11:55:11,028 INFO    SystemMonitor:19815 [system_monitor.py:_start():158] Starting system asset monitoring threads
2023-11-28 11:55:11,028 INFO    HandlerThread:19815 [system_monitor.py:probe():214] Collecting system info
2023-11-28 11:55:11,029 INFO    SystemMonitor:19815 [interfaces.py:start():190] Started cpu monitoring
2023-11-28 11:55:11,030 INFO    SystemMonitor:19815 [interfaces.py:start():190] Started disk monitoring
2023-11-28 11:55:11,031 INFO    SystemMonitor:19815 [interfaces.py:start():190] Started gpu monitoring
2023-11-28 11:55:11,032 INFO    SystemMonitor:19815 [interfaces.py:start():190] Started memory monitoring
2023-11-28 11:55:11,033 INFO    SystemMonitor:19815 [interfaces.py:start():190] Started network monitoring
2023-11-28 11:55:11,059 DEBUG   HandlerThread:19815 [system_info.py:probe():196] Probing system
2023-11-28 11:55:11,066 DEBUG   HandlerThread:19815 [gitlib.py:_init_repo():53] git repository is invalid
2023-11-28 11:55:11,066 DEBUG   HandlerThread:19815 [system_info.py:probe():244] Probing system done
2023-11-28 11:55:11,066 DEBUG   HandlerThread:19815 [system_monitor.py:probe():223] {'os': 'Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.35', 'python': '3.9.18', 'heartbeatAt': '2023-11-28T03:55:11.059154', 'startedAt': '2023-11-28T03:55:10.958261', 'docker': None, 'cuda': None, 'args': ('--model_name_or_path', 'FlagAlpha/Llama2-Chinese-7b-Chat', '--data_path', '/work/u5516210/Huatuo-Llama-Med-Chinese/data/HealthCareMagic-100k-ZHTW_Translate_change_name.json', '--fp16', 'True', '--output_dir', 'model_output/fine_tune_zh', '--num_train_epochs', '1', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '5000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--logging_steps', '1', '--deepspeed', './configs/optm3.json', '--tf32', 'False'), 'state': 'running', 'program': '/work/u5516210/llama-medical-chinese-chatbot/train_my.py', 'codePathLocal': 'train_my.py', 'codePath': 'train_my.py', 'host': 'hcjocdctr1701142396218-4xbjl', 'username': 'u5516210', 'executable': '/home/u5516210/anaconda3/envs/DT/bin/python', 'cpu_count': 36, 'cpu_count_logical': 36, 'cpu_freq': {'current': 3000.0, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}, {'current': 3000.0, 'min': 0.0, 'max': 0.0}], 'disk': {'/': {'total': 100.0, 'used': 0.04933929443359375}}, 'gpu': 'Tesla V100-SXM2-32GB', 'gpu_count': 4, 'gpu_devices': [{'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34089730048}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34089730048}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34089730048}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34089730048}], 'memory': {'total': 754.3754539489746}}
2023-11-28 11:55:11,081 INFO    HandlerThread:19815 [system_monitor.py:probe():224] Finished collecting system info
2023-11-28 11:55:11,081 INFO    HandlerThread:19815 [system_monitor.py:probe():227] Publishing system info
2023-11-28 11:55:11,081 DEBUG   HandlerThread:19815 [system_info.py:_save_pip():52] Saving list of pip packages installed into the current environment
2023-11-28 11:55:11,082 DEBUG   HandlerThread:19815 [system_info.py:_save_pip():68] Saving pip packages done
2023-11-28 11:55:11,082 DEBUG   HandlerThread:19815 [system_info.py:_save_conda():75] Saving list of conda packages installed into the current environment
2023-11-28 11:55:11,088 ERROR   HandlerThread:19815 [system_info.py:_save_conda():86] Error saving conda packages: [Errno 2] No such file or directory: 'conda'
Traceback (most recent call last):
  File "/home/u5516210/.local/lib/python3.9/site-packages/wandb/sdk/internal/system/system_info.py", line 82, in _save_conda
    subprocess.call(
  File "/home/u5516210/anaconda3/envs/DT/lib/python3.9/subprocess.py", line 349, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/home/u5516210/anaconda3/envs/DT/lib/python3.9/subprocess.py", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/home/u5516210/anaconda3/envs/DT/lib/python3.9/subprocess.py", line 1837, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'conda'
2023-11-28 11:55:11,089 DEBUG   HandlerThread:19815 [system_info.py:_save_conda():87] Saving conda packages done
2023-11-28 11:55:11,090 INFO    HandlerThread:19815 [system_monitor.py:probe():229] Finished publishing system info
2023-11-28 11:55:15,978 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:15,978 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:20,980 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:20,980 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:25,982 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:25,982 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:30,984 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:30,984 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:35,986 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:35,986 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:40,987 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:40,988 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:42,661 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: partial_history
2023-11-28 11:55:45,989 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:45,990 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:50,991 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:50,992 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:55:55,993 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:55:55,994 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:00,995 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:00,996 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:05,997 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:05,998 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:10,999 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:10,999 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:11,033 DEBUG   SystemMonitor:19815 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2023-11-28 11:56:12,971 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: partial_history
2023-11-28 11:56:16,001 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:16,001 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:21,002 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:21,003 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:26,004 DEBUG   HandlerThread:19815 [handler.py:handle_request():146] handle_request: status_report
2023-11-28 11:56:26,005 DEBUG   SenderThread:19815 [sender.py:send_request():407] send_request: status_report
2023-11-28 11:56:29,104 INFO    cpu       :19815 [interfaces.py:monitor():140] Process cpu has exited.
2023-11-28 11:56:29,105 DEBUG   SystemMonitor:19815 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2023-11-28 11:56:29,106 DEBUG   SystemMonitor:19815 [system_monitor.py:_start():183] Publishing last batch of metrics
2023-11-28 11:56:30,001 INFO    MainThread:19815 [internal.py:handle_exit():76] Internal process exited
